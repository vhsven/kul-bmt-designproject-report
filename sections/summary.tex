\section*{Summary} %\addcontentsline{toc}{section}{Summary}

The goal of this project is to develop a fully automated algorithm for the
detection of pulmonary nodules in CT scans. A cascaded Random Forests classifier
will be used to assign nodule probabilities to individual voxels. To train the
classifier, 30 datasets from the LIDC/IDRI are used. Voxels in the center of the
nodule are used as positives samples, while negative voxels are randomly sampled
from any image part that is at a safe distance from all nodules. For each of
these voxels, a feature vector is generated and fed into the classifier.
Five-fold cross validation combined with an optimal parameter grid search shows
accuracy increases to 98,2\% in the last cascade level while at the same time
it makes sure the classifier's hyperparameters are properly calibrated to
prevent overfitting.

Once the classifier is trained, we use 8 different datasets from the LIDC/IDRI
database to perform tests and validation. For performance reasons, a lung mask
is calculated of each set before actual testing begins. We propose two lung
segmentation algorithms, one based on thresholds and morphological operations
and another based on region growing. Either of these will provide us with the
initial mask to start the calculations on.

The cascaded classifier comprises of four levels. In the first level, intensity
is used as a feature as it is readily available. This teaches the classifier
that nodules belong to the soft tissue window, allowing it to discard any voxel
outside of that range. The second level feature is a laplacian blob detector
over several scales in addition to a distance map. This allows the classifier to
specifically detect nodule-sized blobs in the 3D image while staying clear of
the lung walls. At the third and fourth level a 3D averaging effect is used to
distinguish between small nodules and other structures such as bronchioli or
blood vessels by taking into account the structures extent in previous and
following slices. Many other features were implemented and tested, but
ultimately did not make the cut.

After the last cascade, roughly 0,5\% of all voxels remain. We found on average
2,17 true positives and 4279,43 false positives per dataset, while maintaining
the number of false negatives at zero. This yields a perfect sensitivity of
100\% but a very low precision of 0,0634\%. This number is so low because our
algorithm is not strict enough yet and we have not implemented a proper false
positives reduction method. On top of that, our number of false positives is
expressed in number of voxelclusters (or ``potential nodules'') while the other
two metrics are expressed in proper nodules. This discrepancy makes comparison
between both metrics very difficult.

%TODO hoe deze resultaten zich verhouden tot de literatuur. Daar weet ik ni zo veel van.. :/

To improve these results, future work will have to continue fine-tuning the
parameters of our algorithms and improve the effectiveness of the features. In
particular the effectiveness of the 3D averaging feature was found lacking.
Raising the cascade threshold after level two also looks promising. Other
options include expanding the number of training sets and implementing new
features. Furthermore, future research should look into more advanced voxel
clustering strategies such that the remaining clusters are properly worthy of
the term ``potential nodule''. We believe that this last step alone would
significantly reduce our false positives and consequently increase the
precision.

%TODO distmap needed? result without?